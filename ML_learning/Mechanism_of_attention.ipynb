{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29db3fea-d1d9-45dd-8c95-cefcc9853b72",
   "metadata": {},
   "source": [
    "# Механизм внимания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb45942-f1c8-4240-88e8-a85820c588fc",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Решить задачу перевода с помощью механизма внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35086f1-5319-4df5-a97e-fef3741becc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8764a19-ebd5-4546-bd0e-61f7e53fd07a",
   "metadata": {},
   "source": [
    "1. **Загрузка и предварительная обработка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921caac1-6956-415a-bde7-1d6c3130cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество английских предложений: 496059\n",
      "Количество русских предложений: 496059\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    eng_sentences = []\n",
    "    rus_sentences = []\n",
    "    # Открываем файл с датасетом\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # Разбиваем строку по табуляции\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                # Добавляем предложения в соответствующие списки, приводим к нижнему регистру\n",
    "                eng_sentences.append(parts[0].lower())\n",
    "                rus_sentences.append(parts[1].lower())\n",
    "    return eng_sentences, rus_sentences\n",
    "\n",
    "# Путь к датасету \n",
    "data_path = 'C:/Users/Yaros/Downloads/rus-eng/rus.txt'\n",
    "\n",
    "# Загружаем данные\n",
    "eng_sentences, rus_sentences = load_data(data_path)\n",
    "\n",
    "# Проверяем количество загруженных предложений\n",
    "print(f\"Количество английских предложений: {len(eng_sentences)}\")\n",
    "print(f\"Количество русских предложений: {len(rus_sentences)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d921f-450a-4510-af53-4a7bf06a96a5",
   "metadata": {},
   "source": [
    "##### Проверяем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfe14d7-d7f4-407c-9b5f-f55f27907608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Английское предложение: in my opinion, we've already done more than enough.\n",
      "Русское предложение: по-моему, мы уже сделали более чем достаточно.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "index = random.randint(0, len(eng_sentences) - 1)\n",
    "print(f\"Английское предложение: {eng_sentences[index]}\")\n",
    "print(f\"Русское предложение: {rus_sentences[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed224b8-e7cd-488e-878e-aad05c9fdf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индексы пустых английских предложений: []\n",
      "Индексы пустых русских предложений: []\n"
     ]
    }
   ],
   "source": [
    "empty_eng = [i for i, sent in enumerate(eng_sentences) if not sent.strip()]\n",
    "empty_rus = [i for i, sent in enumerate(rus_sentences) if not sent.strip()]\n",
    "\n",
    "print(f\"Индексы пустых английских предложений: {empty_eng}\")\n",
    "print(f\"Индексы пустых русских предложений: {empty_rus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f469d2f-9ab7-4aeb-ba56-d28dd803c108",
   "metadata": {},
   "source": [
    "##### Токенизация с использованием spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3b8776-a0a1-4e7a-b8a1-3a23e1ef5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модели spaCy для английского и русского языков\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_ru = spacy.load('ru_core_news_sm')\n",
    "\n",
    "# Токенизаторы на основе spaCy\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_rus(text):\n",
    "    return [tok.text for tok in spacy_ru.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b10d96-6285-40bf-90cc-063f70579768",
   "metadata": {},
   "source": [
    "##### Построение словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079d1742-1b73-406f-8d34-d8d754e634eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер английского словаря: 12903\n",
      "Размер русского словаря: 37064\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(tokenized_sentences, min_freq):\n",
    "    counter = Counter()\n",
    "    for tokens in tokenized_sentences:\n",
    "        counter.update(tokens)\n",
    "    # Начальные специальные токены\n",
    "    vocab = {'<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "    index = 4\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "    return vocab\n",
    "\n",
    "# Токенизируем все предложения\n",
    "eng_tokenized = [tokenize_eng(sentence) for sentence in eng_sentences]\n",
    "rus_tokenized = [tokenize_rus(sentence) for sentence in rus_sentences]\n",
    "\n",
    "# Строим словари с минимальной частотой вхождения\n",
    "eng_vocab = build_vocab(eng_tokenized, min_freq=2)\n",
    "rus_vocab = build_vocab(rus_tokenized, min_freq=2)\n",
    "\n",
    "# Выводим размеры словарей\n",
    "print(f\"Размер английского словаря: {len(eng_vocab)}\")\n",
    "print(f\"Размер русского словаря: {len(rus_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190e764-099d-4473-b84a-a6e497d1d4db",
   "metadata": {},
   "source": [
    "##### Функции для преобразования токенов и индексов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79512102-48ce-42c1-8797-4880d4118875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_indexes(tokens, vocab):\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "\n",
    "def indexes_to_tokens(indexes, vocab):\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}\n",
    "    return [inv_vocab.get(index, '<unk>') for index in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f987715-a309-4577-9037-503c124c846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кастомный класс Dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sentences, trg_sentences, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.trg_sentences = trg_sentences\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence = self.src_sentences[idx]\n",
    "        trg_sentence = self.trg_sentences[idx]\n",
    "        \n",
    "        # Токенизируем и добавляем специальные токены\n",
    "        src_tokens = ['<bos>'] + self.src_tokenizer(src_sentence) + ['<eos>']\n",
    "        trg_tokens = ['<bos>'] + self.trg_tokenizer(trg_sentence) + ['<eos>']\n",
    "        \n",
    "        # Преобразуем токены в индексы\n",
    "        src_indexes = tokens_to_indexes(src_tokens, self.src_vocab)\n",
    "        trg_indexes = tokens_to_indexes(trg_tokens, self.trg_vocab)\n",
    "        \n",
    "        return torch.tensor(src_indexes), torch.tensor(trg_indexes)\n",
    "\n",
    "# Разделяем данные на обучающую и валидационную выборки\n",
    "train_eng, val_eng, train_rus, val_rus = train_test_split(\n",
    "    eng_sentences, rus_sentences, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Создаем экземпляры датасетов\n",
    "train_dataset = TranslationDataset(train_eng, train_rus, tokenize_eng, tokenize_rus, eng_vocab, rus_vocab)\n",
    "val_dataset = TranslationDataset(val_eng, val_rus, tokenize_eng, tokenize_rus, eng_vocab, rus_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e33e91-c58e-4f1b-b2ed-62a1de35ca32",
   "metadata": {},
   "source": [
    "##### Создание DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd34661-9817-4e4b-a372-6823b5834095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=eng_vocab['<pad>'])\n",
    "    trg_batch = pad_sequence(trg_batch, padding_value=rus_vocab['<pad>'])\n",
    "    return src_batch, trg_batch\n",
    "\n",
    "# Размер батча\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Создаем DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76523ee2-2b01-49d1-b403-c99099ce05a5",
   "metadata": {},
   "source": [
    "2. **Определение моделей**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2584c-c286-434c-a3be-ec77dba69465",
   "metadata": {},
   "source": [
    "##### Модель энкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1348a5a8-4529-431a-8796-90092dde4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim  # Сохраняем enc_hid_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [src_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src))  # [src_len, batch_size, emb_dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # Объединяем последние прямое и обратное скрытые состояния\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # [batch_size, enc_hid_dim * 2]\n",
    "        return outputs, hidden  # outputs для внимания, hidden для инициализации декодера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea2f17-591a-4f4d-a60a-8147fc071c05",
   "metadata": {},
   "source": [
    "##### Механизм внимания на основе скалярного произведения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ea6faf-2a6d-4b30-94b5-59805e2dd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # Линейные слои для преобразования размерностей\n",
    "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [batch_size, dec_hid_dim]\n",
    "        # encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        # Повторяем скрытое состояние декодера src_len раз\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch_size, src_len, dec_hid_dim]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # [batch_size, src_len, enc_hid_dim * 2]\n",
    "\n",
    "        # Вычисляем энергию\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # [batch_size, src_len, dec_hid_dim]\n",
    "        attention = self.v(energy).squeeze(2)  # [batch_size, src_len]\n",
    "\n",
    "        return torch.softmax(attention, dim=1)  # [batch_size, src_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a96941-6b97-4d3f-a27c-fac36fc459f8",
   "metadata": {},
   "source": [
    "##### Механизм внимания на основе MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d713a4e9-47a9-4cf6-a391-823a842dc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPAttention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        # Линейные слои для преобразования размерностей\n",
    "        self.attn = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Аналогично DotProductAttention\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        return torch.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd05c5-a093-4cff-969f-0b05a30fbac8",
   "metadata": {},
   "source": [
    "##### Модель декодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13130012-cf15-4c71-84ac-3fed76f63fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, attention):\n",
    "        super().__init__()\n",
    "        self.dec_hid_dim = dec_hid_dim  # Сохраняем dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(emb_dim + enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.fc_out = nn.Linear(emb_dim + dec_hid_dim + enc_hid_dim * 2, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input: [batch_size]\n",
    "        # hidden: [batch_size, dec_hid_dim]\n",
    "        # encoder_outputs: [src_len, batch_size, enc_hid_dim * 2]\n",
    "\n",
    "        input = input.unsqueeze(0)  # [1, batch_size]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))  # [1, batch_size, emb_dim]\n",
    "\n",
    "        # Вычисляем веса внимания\n",
    "        a = self.attention(hidden, encoder_outputs)  # [batch_size, src_len]\n",
    "        a = a.unsqueeze(1)  # [batch_size, 1, src_len]\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # [batch_size, src_len, enc_hid_dim * 2]\n",
    "\n",
    "        # Вычисляем контекстный вектор\n",
    "        weighted = torch.bmm(a, encoder_outputs)  # [batch_size, 1, enc_hid_dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)  # [1, batch_size, enc_hid_dim * 2]\n",
    "\n",
    "        # Соединяем эмбеддинг и контекст\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)  # [1, batch_size, emb_dim + enc_hid_dim * 2]\n",
    "\n",
    "        # Передаем через GRU\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))  # output: [1, batch_size, dec_hid_dim]\n",
    "\n",
    "        # Упрощаем размерности\n",
    "        embedded = embedded.squeeze(0)  # [batch_size, emb_dim]\n",
    "        output = output.squeeze(0)      # [batch_size, dec_hid_dim]\n",
    "        weighted = weighted.squeeze(0)  # [batch_size, enc_hid_dim * 2]\n",
    "\n",
    "        # Предсказываем следующее слово\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))  # [batch_size, output_dim]\n",
    "\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e972fd-03b4-433f-8130-5a68ab94c888",
   "metadata": {},
   "source": [
    "##### Модель Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88b44bb9-3057-46a5-9ea4-ad3ad4fe8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        # Новый линейный слой для преобразования скрытого состояния\n",
    "        self.fc_hidden = nn.Linear(encoder.enc_hid_dim * 2, decoder.dec_hid_dim)\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [src_len, batch_size]\n",
    "        # trg: [trg_len, batch_size]\n",
    "\n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # Тензор для хранения выходов декодера\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # Передаем через энкодер\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # Преобразуем скрытое состояние энкодера для декодера\n",
    "        dec_hidden = torch.tanh(self.fc_hidden(hidden))  # [batch_size, dec_hid_dim]\n",
    "\n",
    "        # Первый вход декодера - токен <bos>\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            # Передаем через декодер\n",
    "            output, dec_hidden = self.decoder(input, dec_hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            # Решаем, использовать ли teacher forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ff234-3768-489c-b0cc-ddb1d335c6cb",
   "metadata": {},
   "source": [
    "3. **Обучение модели**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e6c18-5f2d-4bcf-8053-3efd1b487dfd",
   "metadata": {},
   "source": [
    "##### Инициализация модели и оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eedc1f9-eae0-48c0-a939-4b705a32e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем размеры\n",
    "INPUT_DIM = len(eng_vocab)\n",
    "OUTPUT_DIM = len(rus_vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "\n",
    "# Устройство\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Инициализируем механизм внимания\n",
    "attn = DotProductAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "# Для MLP Attention, замените на:\n",
    "# attn = MLPAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "\n",
    "# Инициализируем энкодер и декодер\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, attn)\n",
    "\n",
    "# Создаем модель Seq2Seq с обновленным классом\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# Инициализируем оптимизатор\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Функция потерь, игнорируем индекс паддинга\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=rus_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222b6b9-d3c2-407a-9c2b-c51d21a2bfa2",
   "metadata": {},
   "source": [
    "##### Функции обучения и оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9a3ad45-e1cb-4aa4-b80f-5fa58ff3dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # output: [trg_len, batch_size, output_dim]\n",
    "        # trg: [trg_len, batch_size]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # Убираем первый токен и перестраиваем для вычисления потерь\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Градиентный клиппинг\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, 0)  # Отключаем teacher forcing\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb868b3-0ed1-4bf7-b417-0ebed6664dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cdc4f-10b8-4c06-adec-1269fc4ce73c",
   "metadata": {},
   "source": [
    "##### Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "934f8bfb-9658-4627-8e6c-3509f626d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 01\n",
      "\tПотеря на обучении: 2.749\n",
      "\tПотеря на валидации: 2.815\n",
      "Эпоха: 02\n",
      "\tПотеря на обучении: 2.297\n",
      "\tПотеря на валидации: 2.835\n",
      "Эпоха: 03\n",
      "\tПотеря на обучении: 2.246\n",
      "\tПотеря на валидации: 2.948\n",
      "Эпоха: 04\n",
      "\tПотеря на обучении: 2.250\n",
      "\tПотеря на валидации: 2.982\n",
      "Эпоха: 05\n",
      "\tПотеря на обучении: 2.277\n",
      "\tПотеря на валидации: 3.039\n",
      "Эпоха: 06\n",
      "\tПотеря на обучении: 2.321\n",
      "\tПотеря на валидации: 3.127\n",
      "Эпоха: 07\n",
      "\tПотеря на обучении: 2.388\n",
      "\tПотеря на валидации: 3.219\n",
      "Эпоха: 08\n",
      "\tПотеря на обучении: 2.468\n",
      "\tПотеря на валидации: 3.332\n",
      "Эпоха: 09\n",
      "\tПотеря на обучении: 2.569\n",
      "\tПотеря на валидации: 3.424\n",
      "Эпоха: 10\n",
      "\tПотеря на обучении: 2.668\n",
      "\tПотеря на валидации: 3.455\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f'Эпоха: {epoch+1:02}')\n",
    "    print(f'\\tПотеря на обучении: {train_loss:.3f}')\n",
    "    print(f'\\tПотеря на валидации: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925dc32b-7578-43b1-be38-28c672db4242",
   "metadata": {},
   "source": [
    "4. Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e6ddfdb-11c0-4cff-94a9-afbe0f2812ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, src_tokenizer, src_vocab, trg_vocab, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = ['<bos>'] + src_tokenizer(sentence.lower()) + ['<eos>']\n",
    "    src_indexes = tokens_to_indexes(tokens, src_vocab)\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "        # Преобразуем скрытое состояние энкодера для декодера\n",
    "        dec_hidden = torch.tanh(model.fc_hidden(hidden))\n",
    "\n",
    "    trg_indexes = [trg_vocab['<bos>']]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, dec_hidden = model.decoder(trg_tensor, dec_hidden, encoder_outputs)\n",
    "\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    trg_tokens = indexes_to_tokens(trg_indexes, trg_vocab)\n",
    "\n",
    "    return trg_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e3cf749-25df-4a18-b1c8-96187c242199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перевод: привет привет , как поживаете ? <eos>\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hello, how are you?\"\n",
    "translated_tokens = translate_sentence(model, sentence, tokenize_eng, eng_vocab, rus_vocab)\n",
    "translated_sentence = ' '.join(translated_tokens)\n",
    "print(f\"Перевод: {translated_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a8a89-6afd-4a49-8a80-9ff4860f80ef",
   "metadata": {},
   "source": [
    "##### Вычисление BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35eb9c7e-c0d2-4c02-99de-65390e30b656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score = 19.87\n"
     ]
    }
   ],
   "source": [
    "def calculate_bleu(model, dataset, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab, n_examples=100):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "\n",
    "    for i in range(n_examples):\n",
    "        src_sentence = dataset.src_sentences[i]\n",
    "        trg_sentence = dataset.trg_sentences[i]\n",
    "        \n",
    "        pred_trg = translate_sentence(model, src_sentence, src_tokenizer, src_vocab, trg_vocab)\n",
    "        pred_trg = [token for token in pred_trg if token not in ['<eos>', '<pad>']]\n",
    "        \n",
    "        trg_tokens = trg_tokenizer(trg_sentence)\n",
    "        \n",
    "        trgs.append([trg_tokens])\n",
    "        pred_trgs.append(pred_trg)\n",
    "\n",
    "    bleu = corpus_bleu(trgs, pred_trgs)\n",
    "    return bleu\n",
    "\n",
    "# Вычисляем BLEU Score на валидационном наборе\n",
    "bleu_score = calculate_bleu(model, val_dataset, tokenize_eng, tokenize_rus, eng_vocab, rus_vocab)\n",
    "print(f'BLEU Score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ff8fa1e-0804-4955-acd5-d65d97d3f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score on validation set: 19.87\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(model, val_dataset, tokenize_eng, tokenize_rus, eng_vocab, rus_vocab, n_examples=100)\n",
    "print(f'BLEU Score on validation set: {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff66acd6-ae7f-48a5-9124-aeee6080551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: it seems you were right.\n",
      "Target: похоже, ты была права.\n",
      "Predicted: кажется , ты правы права . <eos>\n",
      "--------------------------------------------------\n",
      "Source: if there are no dogs in heaven, then when i die i want to go where they went.\n",
      "Target: если в раю нет собак, то после смерти я хочу отправиться туда, куда ушли они.\n",
      "Predicted: если я не в школьной , , , когда захочешь я туда , куда они пошли . <eos>\n",
      "--------------------------------------------------\n",
      "Source: i'll wash the dog.\n",
      "Target: я искупаю собаку.\n",
      "Predicted: я помою собаку . <eos>\n",
      "--------------------------------------------------\n",
      "Source: do you have a car?\n",
      "Target: у вас машина есть?\n",
      "Predicted: у вас есть машина есть машине ? <eos>\n",
      "--------------------------------------------------\n",
      "Source: i'm glad you're here today.\n",
      "Target: я рада, что вы сегодня здесь.\n",
      "Predicted: рад рад , что ты здесь сегодня . <eos>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    src_sentence = val_dataset.src_sentences[i]\n",
    "    trg_sentence = val_dataset.trg_sentences[i]\n",
    "    \n",
    "    pred_trg = translate_sentence(model, src_sentence, tokenize_eng, eng_vocab, rus_vocab)\n",
    "    pred_sentence = ' '.join(pred_trg)\n",
    "    \n",
    "    print(f\"Source: {src_sentence}\")\n",
    "    print(f\"Target: {trg_sentence}\")\n",
    "    print(f\"Predicted: {pred_sentence}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cb262-8295-4bf8-921f-e145cba55635",
   "metadata": {},
   "source": [
    "##### Обучим модель с MLPAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2001678a-e4e1-4d48-9518-7af5d3eba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем механизм внимания\n",
    "attn = MLPAttention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "\n",
    "# Инициализируем энкодер и декодер с новым механизмом внимания\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, attn)\n",
    "\n",
    "# Создаем новую модель Seq2Seq\n",
    "model_mlp = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "\n",
    "optimizer_mlp = optim.Adam(model_mlp.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6842c0af-2b6b-436d-8415-1456e83bec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 01\n",
      "\tПотеря на обучении: 2.748\n",
      "\tПотеря на валидации: 2.878\n",
      "Эпоха: 02\n",
      "\tПотеря на обучении: 2.299\n",
      "\tПотеря на валидации: 2.850\n",
      "Эпоха: 03\n",
      "\tПотеря на обучении: 2.253\n",
      "\tПотеря на валидации: 2.957\n",
      "Эпоха: 04\n",
      "\tПотеря на обучении: 2.263\n",
      "\tПотеря на валидации: 3.101\n",
      "Эпоха: 05\n",
      "\tПотеря на обучении: 2.289\n",
      "\tПотеря на валидации: 3.063\n",
      "Эпоха: 06\n",
      "\tПотеря на обучении: 2.330\n",
      "\tПотеря на валидации: 3.229\n",
      "Эпоха: 07\n",
      "\tПотеря на обучении: 2.416\n",
      "\tПотеря на валидации: 3.242\n",
      "Эпоха: 08\n",
      "\tПотеря на обучении: 2.492\n",
      "\tПотеря на валидации: 3.452\n",
      "Эпоха: 09\n",
      "\tПотеря на обучении: 2.600\n",
      "\tПотеря на валидации: 3.469\n",
      "Эпоха: 10\n",
      "\tПотеря на обучении: 2.702\n",
      "\tПотеря на валидации: 3.498\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model_mlp, train_loader, optimizer_mlp, criterion, CLIP)\n",
    "    val_loss = evaluate(model_mlp, val_loader, criterion)\n",
    "\n",
    "    print(f'Эпоха: {epoch+1:02}')\n",
    "    print(f'\\tПотеря на обучении: {train_loss:.3f}')\n",
    "    print(f'\\tПотеря на валидации: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb097ec-ed16-4bdf-a1e3-51762e5209e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score with MLP Attention = 16.45\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем BLEU Score для модели с MLPAttention\n",
    "bleu_score_mlp = calculate_bleu(model_mlp, val_dataset, tokenize_eng, tokenize_rus, eng_vocab, rus_vocab)\n",
    "print(f'BLEU Score with MLP Attention = {bleu_score_mlp*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59974c9-69e1-470a-966e-2a13652a5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: it seems you were right.\n",
      "Target: похоже, ты была права.\n",
      "Predicted with MLP Attention: похоже , похоже прав . <eos>\n",
      "--------------------------------------------------\n",
      "Source: if there are no dogs in heaven, then when i die i want to go where they went.\n",
      "Target: если в раю нет собак, то после смерти я хочу отправиться туда, куда ушли они.\n",
      "Predicted with MLP Attention: если бы нет в от гостей , куда я хочу . <eos>\n",
      "--------------------------------------------------\n",
      "Source: i'll wash the dog.\n",
      "Target: я искупаю собаку.\n",
      "Predicted with MLP Attention: я помою собаку собаку . <eos>\n",
      "--------------------------------------------------\n",
      "Source: do you have a car?\n",
      "Target: у вас машина есть?\n",
      "Predicted with MLP Attention: у тебя есть машина машины <eos>\n",
      "--------------------------------------------------\n",
      "Source: i'm glad you're here today.\n",
      "Target: я рада, что вы сегодня здесь.\n",
      "Predicted with MLP Attention: я рад , что сегодня здесь сегодня . <eos>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    src_sentence = val_dataset.src_sentences[i]\n",
    "    trg_sentence = val_dataset.trg_sentences[i]\n",
    "    \n",
    "    pred_trg = translate_sentence(model_mlp, src_sentence, tokenize_eng, eng_vocab, rus_vocab)\n",
    "    pred_sentence = ' '.join(pred_trg)\n",
    "    \n",
    "    print(f\"Source: {src_sentence}\")\n",
    "    print(f\"Target: {trg_sentence}\")\n",
    "    print(f\"Predicted with MLP Attention: {pred_sentence}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "860667eb-eefa-42e2-a444-b9a26db55ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score with Dot-product Attention = 19.87\n",
      "BLEU Score with MLP Attention = 16.45\n"
     ]
    }
   ],
   "source": [
    "# Вывод BLEU Score для обеих моделей\n",
    "print(f'BLEU Score with Dot-product Attention = {bleu_score*100:.2f}')\n",
    "print(f'BLEU Score with MLP Attention = {bleu_score_mlp*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ab33e-1070-4b08-ae1b-19be7d93079b",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В этой работе я выполнил задачу перевода с английского на русский с использованием двух механизмов внимания: на основе скалярного произведения (DotProductAttention) и на основе многоуровневого перцептрона (MLPAttention). Обе модели были обучены на англо-русских парах предложений, а качество их работы я оценил с помощью BLEU Score и примеров переводов.\n",
    "\n",
    "**Результаты:**\n",
    "1) BLEU Score:\n",
    "\n",
    "    - Модель с DotProductAttention показала BLEU Score = 19.87.\n",
    "    - Модель с MLPAttention показала более низкий результат BLEU Score = 16.45.\n",
    "      \n",
    "2) Примеры переводов:\n",
    "\n",
    "    - Переводы, выполненные моделью с DotProductAttention, были более осмысленными, хотя в некоторых случаях встречались повторения слов и небольшие ошибки.\n",
    "    - Модель с MLPAttention часто допускала повторение слов и создавала менее логичные конструкции предложений. Например, в переводе вопроса \"Do you have a car?\" было неправильное повторение слов: \"у тебя есть машина машины\".\n",
    "\n",
    "3) Сравнение:\n",
    "\n",
    "    - Модель с DotProductAttention показала себя более точной и стабильной, как по BLEU Score, так и по качеству переводов. Она генерировала более осмысленные фразы, хотя и не без ошибок.\n",
    "    - Модель с MLPAttention, несмотря на свою гибкость, продемонстрировала худшие результаты. Это может указывать на то, что MLP требует более тонкой настройки или большего объёма данных для достижения результатов, сравнимых с DotProductAttention.\n",
    "\n",
    "В ходе работы я осознал, что для повышения качества перевода необходимо:  \n",
    "    - **Настроить гиперпараметры модели:** Возможно, стоит изменить скорость обучения, размер батча или использовать методы регуляризации, чтобы избежать переобучения.  \n",
    "    - **Увеличить количество эпох обучения:** Но при этом необходимо контролировать переобучение и, при необходимости, использовать раннюю остановку.  \n",
    "    - **Использовать предобученные эмбеддинги:** Внедрение GloVe, FastText или других предобученных эмбеддингов может улучшить качество представлений слов и, соответственно, перевода.  \n",
    "    - **Применить подсловные токены:** Использование методов, таких как Byte Pair Encoding (BPE), может помочь модели лучше обрабатывать редкие или незнакомые слова.  \n",
    "    \n",
    "В целом, проделанная работа позволила мне глубже понять принципы работы моделей Seq2Seq с механизмом внимания и особенности их обучения на реальных данных. Полученные результаты служат основой для дальнейших экспериментов и улучшений модели. Я планирую продолжить исследования в этом направлении, внедрить предложенные улучшения и оценить их влияние на качество перевода."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
