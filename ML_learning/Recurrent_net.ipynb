{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64973f20-c803-46c8-8eb0-8fcb69d1c850",
   "metadata": {},
   "source": [
    "# Рекуррентные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c33461-05f4-4a6a-acc5-bf34c63eb420",
   "metadata": {},
   "source": [
    "## **Задание 1.**  \n",
    "**Обучить нейронную сеть решать шифр Цезаря**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0d3b0-52e0-49a4-8137-5cc5ecb8f51a",
   "metadata": {},
   "source": [
    "1. Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4c0a592-0bc3-4fa6-aad1-9cf971214fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92e07f8f-05fd-4e18-a658-baeb7a9004e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 1: Генерация выборки\n",
    "\n",
    "def generate_caesar_cipher(text, shift):\n",
    "    \"\"\"\n",
    "    Функция для шифрования текста с помощью шифра Цезаря.\n",
    "    \"\"\"\n",
    "    alphabet = string.ascii_lowercase + ' '  # Добавляем пробел в алфавит\n",
    "    shifted_alphabet = alphabet[shift:] + alphabet[:shift]  # Сдвинутый алфавит\n",
    "    table = str.maketrans(alphabet, shifted_alphabet)  # Таблица преобразований\n",
    "    return text.translate(table)  # Применяем преобразования к тексту\n",
    "\n",
    "def generate_dataset(num_samples, shift):\n",
    "    \"\"\"\n",
    "    Функция для генерации выборки данных.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for _ in range(num_samples):\n",
    "        text_length = random.randint(5, 15)  # Случайная длина текста\n",
    "        text = ''.join(random.choices(string.ascii_lowercase + ' ', k=text_length))  # Случайный текст\n",
    "        encrypted_text = generate_caesar_cipher(text, shift)  # Шифруем текст\n",
    "        dataset.append((encrypted_text, text))  # Добавляем пару в выборку\n",
    "    return dataset\n",
    "\n",
    "# Параметры генерации данных\n",
    "shift = 2  # Сдвиг для шифра Цезаря\n",
    "num_samples = 1000  # Количество образцов\n",
    "dataset = generate_dataset(num_samples, shift)  # Генерируем выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b0a2b9-256e-4cac-b613-8f152406e2cf",
   "metadata": {},
   "source": [
    "2. Сделать нейронную сеть (в данном пункте подшотовим данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b01d13cd-781e-466e-978d-75321fdaecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 2: Подготовка данных для обучения\n",
    "\n",
    "chars = list(string.ascii_lowercase + ' ')  # Список символов\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}  # Символ в индекс\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}  # Индекс в символ\n",
    "\n",
    "class CaesarCipherDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс датасета для шифра Цезаря.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, char_to_idx):\n",
    "        self.data = data\n",
    "        self.char_to_idx = char_to_idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        encrypted_text, original_text = self.data[idx]\n",
    "        input_seq = torch.tensor([self.char_to_idx[c] for c in encrypted_text], dtype=torch.long)\n",
    "        target_seq = torch.tensor([self.char_to_idx[c] for c in original_text], dtype=torch.long)\n",
    "        return input_seq, target_seq\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Функция для объединения списка образцов в батч.\n",
    "    \"\"\"\n",
    "    input_seqs, target_seqs = zip(*batch)\n",
    "    input_seqs_padded = nn.utils.rnn.pad_sequence(input_seqs, padding_value=char_to_idx[' '])\n",
    "    target_seqs_padded = nn.utils.rnn.pad_sequence(target_seqs, padding_value=char_to_idx[' '])\n",
    "    return input_seqs_padded, target_seqs_padded\n",
    "\n",
    "dataset = CaesarCipherDataset(dataset, char_to_idx)  # Создаем датасет\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12da440-d68d-4a90-9ac3-42f90743b075",
   "metadata": {},
   "source": [
    "3. Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfc9950-45b8-46c9-a833-c69a08256eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/10, Потеря: 2.1839\n",
      "Эпоха 2/10, Потеря: 0.8702\n",
      "Эпоха 3/10, Потеря: 0.1890\n",
      "Эпоха 4/10, Потеря: 0.0936\n",
      "Эпоха 5/10, Потеря: 0.0725\n",
      "Эпоха 6/10, Потеря: 0.0635\n",
      "Эпоха 7/10, Потеря: 0.0548\n",
      "Эпоха 8/10, Потеря: 0.0494\n",
      "Эпоха 9/10, Потеря: 0.0436\n",
      "Эпоха 10/10, Потеря: 0.0383\n"
     ]
    }
   ],
   "source": [
    "# Шаг 3: Создание и обучение модели\n",
    "\n",
    "class CaesarCipherModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс модели для дешифровки шифра Цезаря.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CaesarCipherModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "def train(model, dataloader, num_epochs, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for input_seqs, target_seqs in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seqs)\n",
    "            output = output.view(-1, output_size)\n",
    "            target = target_seqs.view(-1)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Эпоха {epoch+1}/{num_epochs}, Потеря: {avg_loss:.4f}\")\n",
    "\n",
    "input_size = len(chars)\n",
    "hidden_size = 128\n",
    "output_size = len(chars)\n",
    "num_epochs = 10\n",
    "\n",
    "model = CaesarCipherModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model, dataloader, num_epochs, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4dc5eb-e73d-488d-af16-794339d09fd3",
   "metadata": {},
   "source": [
    "4. Проверить качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e37cb5f4-1c2c-4fa7-85b6-87846ae20d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зашифрованный текст: jgnnqbyqtnf\n",
      "Предсказанный текст: hello world\n",
      "Оригинальный текст: hello world\n",
      "Точность декодирования: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Шаг 4: Проверка модели\n",
    "\n",
    "def decode_sequence(output_seq):\n",
    "    \"\"\"\n",
    "    Функция для декодирования выходной последовательности модели.\n",
    "    \"\"\"\n",
    "    _, predicted_indices = torch.max(output_seq, dim=2)\n",
    "    predicted_text = ''.join([idx_to_char[idx.item()] for idx in predicted_indices.squeeze()])\n",
    "    return predicted_text\n",
    "\n",
    "model.eval()\n",
    "test_text = 'hello world'\n",
    "encrypted_test_text = generate_caesar_cipher(test_text, shift)\n",
    "input_seq = torch.tensor([char_to_idx[c] for c in encrypted_test_text], dtype=torch.long).unsqueeze(1)\n",
    "with torch.no_grad():\n",
    "    output = model(input_seq)\n",
    "predicted_text = decode_sequence(output)\n",
    "print(f\"Зашифрованный текст: {encrypted_test_text}\")\n",
    "print(f\"Предсказанный текст: {predicted_text}\")\n",
    "print(f\"Оригинальный текст: {test_text}\")\n",
    "\n",
    "# Анализ точности\n",
    "correct_chars = sum([predicted_text[i] == test_text[i] for i in range(len(test_text))])\n",
    "accuracy = correct_chars / len(test_text) * 100\n",
    "print(f\"Точность декодирования: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc249e6d-50dc-4fa9-ad5c-aa9cf706aa3f",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "В процессе выполнения задания я успешно разработал нейронную сеть, способную дешифровать сообщения, зашифрованные шифром Цезаря. Для достижения этой цели я выполнил следующие шаги:\n",
    "\n",
    "1) **Генерация выборки:**\n",
    "\n",
    "    - Реализовал функцию generate_caesar_cipher, которая осуществляет шифрование текста с заданным сдвигом.\n",
    "    - Создал функцию generate_dataset для генерации выборки пар вида (зашифрованный текст, исходный текст).\n",
    "      \n",
    "2) **Создание нейронной сети:**\n",
    "\n",
    "    - Определил класс CaesarCipherModel, использующий архитектуру LSTM для обработки последовательностей символов.\n",
    "    - В модели задействовал следующие слои:\n",
    "        a) Embedding для преобразования символов в векторные представления.  \n",
    "        b) LSTM для обработки последовательностей.  \n",
    "        c) Linear для преобразования выходов LSTM в вероятности символов.\n",
    "      \n",
    "3) **Обучение модели:**\n",
    "\n",
    "    - Подготовил данные для обучения:\n",
    "        a) Создал словари char_to_idx и idx_to_char для преобразования символов в индексы и обратно.  \n",
    "        b) Реализовал класс CaesarCipherDataset, наследующий от torch.utils.data.Dataset.\n",
    "    - Написал функцию train для обучения модели:\n",
    "        a) Использовал функцию потерь CrossEntropyLoss.  \n",
    "        b) Применил оптимизатор Adam.\n",
    "    - Обучил модель на сгенерированной выборке данных.\n",
    "      \n",
    "4) **Проверка качества:**\n",
    "\n",
    "    - Разработал функцию decode_sequence для декодирования выходной последовательности модели в текст.\n",
    "    - Протестировал модель на новом зашифрованном сообщении:\n",
    "```python\n",
    "Зашифрованный текст: jgnnq yqtnf\n",
    "Предсказанный текст: hello world\n",
    "Оригинальный текст: hello world\n",
    "Точность декодирования: 100.00%\n",
    "```\n",
    "    - Вычислил точность декодирования, которая составила 100%, подтвердив эффективность модели.\n",
    "    \n",
    "**Дополнительные действия:**\n",
    "\n",
    "    - Исправил возникшую ошибку NameError: name 'shift' is not defined, добавив определение переменной shift перед ее использованием в коде проверки модели.  \n",
    "    \n",
    "### Заключение\n",
    "\n",
    "В результате работы я создал нейронную сеть, которая успешно дешифрует сообщения, зашифрованные шифром Цезаря с фиксированным сдвигом. Модель показала высокую точность на тестовых данных, полностью восстанавливая исходный текст из зашифрованного. Этот проект продемонстрировал применение рекуррентных нейронных сетей для решения задач последовательной обработки данных и дешифровки. В процессе разработки я также успешно устранил возникшие ошибки, что подтвердило корректность и надежность реализованного решения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205c169-7e30-4cd6-857e-e2704f337d82",
   "metadata": {},
   "source": [
    "## **Задание 2.**  \n",
    "**Выполнить практическую работу**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41274efa-9c96-4f7e-b285-851a03702d39",
   "metadata": {},
   "source": [
    "1. Построить RNN-ячейку на основе полносвязных слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02872c5-300f-4afe-a8d0-8baa64f9789b",
   "metadata": {},
   "source": [
    "Импортируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb1a7832-f42b-40a6-bac8-31f0796511e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>number</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>timestamp_in_ms</th>\n",
       "      <th>speaking_line</th>\n",
       "      <th>character_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>raw_location_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9549</td>\n",
       "      <td>32</td>\n",
       "      <td>209</td>\n",
       "      <td>Miss Hoover: No, actually, it was a little of ...</td>\n",
       "      <td>848000</td>\n",
       "      <td>true</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9550</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?</td>\n",
       "      <td>856000</td>\n",
       "      <td>true</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9551</td>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Miss Hoover: I don't know. Although I'd sure l...</td>\n",
       "      <td>856000</td>\n",
       "      <td>true</td>\n",
       "      <td>464</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552</td>\n",
       "      <td>32</td>\n",
       "      <td>212</td>\n",
       "      <td>Lisa Simpson: That life is worth living.</td>\n",
       "      <td>864000</td>\n",
       "      <td>true</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>That life is worth living.</td>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9553</td>\n",
       "      <td>32</td>\n",
       "      <td>213</td>\n",
       "      <td>Edna Krabappel-Flanders: The polls will be ope...</td>\n",
       "      <td>864000</td>\n",
       "      <td>true</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>Springfield Elementary School</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  episode_id  number  \\\n",
       "0  9549          32     209   \n",
       "1  9550          32     210   \n",
       "2  9551          32     211   \n",
       "3  9552          32     212   \n",
       "4  9553          32     213   \n",
       "\n",
       "                                            raw_text timestamp_in_ms  \\\n",
       "0  Miss Hoover: No, actually, it was a little of ...          848000   \n",
       "1  Lisa Simpson: (NEAR TEARS) Where's Mr. Bergstrom?          856000   \n",
       "2  Miss Hoover: I don't know. Although I'd sure l...          856000   \n",
       "3           Lisa Simpson: That life is worth living.          864000   \n",
       "4  Edna Krabappel-Flanders: The polls will be ope...          864000   \n",
       "\n",
       "  speaking_line character_id  location_id       raw_character_text  \\\n",
       "0          true          464          3.0              Miss Hoover   \n",
       "1          true            9          3.0             Lisa Simpson   \n",
       "2          true          464          3.0              Miss Hoover   \n",
       "3          true            9          3.0             Lisa Simpson   \n",
       "4          true           40          3.0  Edna Krabappel-Flanders   \n",
       "\n",
       "               raw_location_text  \\\n",
       "0  Springfield Elementary School   \n",
       "1  Springfield Elementary School   \n",
       "2  Springfield Elementary School   \n",
       "3  Springfield Elementary School   \n",
       "4  Springfield Elementary School   \n",
       "\n",
       "                                        spoken_words  \\\n",
       "0  No, actually, it was a little of both. Sometim...   \n",
       "1                             Where's Mr. Bergstrom?   \n",
       "2  I don't know. Although I'd sure like to talk t...   \n",
       "3                         That life is worth living.   \n",
       "4  The polls will be open from now until the end ...   \n",
       "\n",
       "                                     normalized_text word_count  \n",
       "0  no actually it was a little of both sometimes ...         31  \n",
       "1                                wheres mr bergstrom          3  \n",
       "2  i dont know although id sure like to talk to h...         22  \n",
       "3                          that life is worth living          5  \n",
       "4  the polls will be open from now until the end ...         33  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из файла\n",
    "file_path = 'C:/Users/Yaros/Downloads/simpsons_script_lines.csv'\n",
    "simpsons_data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Просмотр первых строк для понимания структуры данных\n",
    "simpsons_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e46fca26-8d38-4ecf-8321-7a8b6d305a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([26,\n",
       "  27,\n",
       "  0,\n",
       "  13,\n",
       "  15,\n",
       "  32,\n",
       "  33,\n",
       "  13,\n",
       "  24,\n",
       "  24,\n",
       "  37,\n",
       "  0,\n",
       "  21,\n",
       "  32,\n",
       "  0,\n",
       "  35,\n",
       "  13,\n",
       "  31,\n",
       "  0,\n",
       "  13,\n",
       "  0,\n",
       "  24,\n",
       "  21,\n",
       "  32,\n",
       "  32,\n",
       "  24,\n",
       "  17,\n",
       "  0,\n",
       "  27,\n",
       "  18,\n",
       "  0,\n",
       "  14,\n",
       "  27,\n",
       "  32,\n",
       "  20,\n",
       "  0,\n",
       "  31,\n",
       "  27,\n",
       "  25,\n",
       "  17,\n",
       "  32,\n",
       "  21,\n",
       "  25,\n",
       "  17,\n",
       "  31,\n",
       "  0,\n",
       "  35,\n",
       "  20,\n",
       "  17,\n",
       "  26,\n",
       "  0,\n",
       "  13,\n",
       "  0,\n",
       "  16,\n",
       "  21,\n",
       "  31,\n",
       "  17,\n",
       "  13,\n",
       "  31,\n",
       "  17,\n",
       "  0,\n",
       "  21,\n",
       "  31,\n",
       "  0,\n",
       "  21,\n",
       "  26,\n",
       "  0,\n",
       "  13,\n",
       "  24,\n",
       "  24,\n",
       "  0,\n",
       "  32,\n",
       "  20,\n",
       "  17,\n",
       "  0,\n",
       "  25,\n",
       "  13,\n",
       "  19,\n",
       "  13,\n",
       "  38,\n",
       "  21,\n",
       "  26,\n",
       "  17,\n",
       "  31,\n",
       "  0,\n",
       "  13,\n",
       "  26,\n",
       "  16,\n",
       "  0,\n",
       "  13,\n",
       "  24,\n",
       "  24,\n",
       "  0,\n",
       "  32,\n",
       "  20,\n",
       "  17,\n",
       "  0,\n",
       "  26,\n",
       "  17,\n",
       "  35,\n",
       "  31,\n",
       "  0,\n",
       "  31,\n",
       "  20,\n",
       "  27,\n",
       "  35,\n",
       "  31,\n",
       "  0,\n",
       "  21,\n",
       "  32,\n",
       "  31,\n",
       "  0,\n",
       "  27,\n",
       "  26,\n",
       "  24,\n",
       "  37,\n",
       "  0,\n",
       "  26,\n",
       "  13,\n",
       "  32,\n",
       "  33,\n",
       "  30,\n",
       "  13,\n",
       "  24,\n",
       "  0,\n",
       "  32,\n",
       "  20,\n",
       "  13,\n",
       "  32,\n",
       "  0,\n",
       "  37,\n",
       "  27,\n",
       "  33,\n",
       "  0,\n",
       "  32,\n",
       "  20,\n",
       "  21,\n",
       "  26,\n",
       "  23,\n",
       "  0,\n",
       "  37,\n",
       "  27,\n",
       "  33,\n",
       "  0,\n",
       "  20,\n",
       "  13,\n",
       "  34,\n",
       "  17,\n",
       "  0,\n",
       "  21,\n",
       "  32],\n",
       " 'no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Извлекаем нормализованный текст\n",
    "phrases = simpsons_data['normalized_text'].dropna().tolist()\n",
    "\n",
    "# Ограничим количество фраз для быстрого обучения\n",
    "phrases = phrases[:10000]\n",
    "\n",
    "# Преобразуем символы в индексы\n",
    "chars = sorted(list(set(''.join(phrases))))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "# Преобразуем текст в числовые последовательности\n",
    "def text_to_sequence(text):\n",
    "    return [char_to_idx[char] for char in text]\n",
    "\n",
    "sequences = [text_to_sequence(phrase) for phrase in phrases]\n",
    "\n",
    "# Проверим результат преобразования на одном примере\n",
    "sequences[0], phrases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c13574-d667-45cc-948e-baf151cffe0e",
   "metadata": {},
   "source": [
    "- Создадим RNN-модель на основе полносвязных слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e0cedef-08e7-43f2-b963-ec99a4f7a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "# Параметры\n",
    "vocab_size = len(chars)\n",
    "embedding_dim = 64\n",
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "seq_length = 100  # Ограничим длину последовательностей\n",
    "\n",
    "# Подготовка данных: паддинг и деление на батчи\n",
    "class SimpsonsDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        # Ограничиваем длину последовательности до seq_length\n",
    "        sequence = sequence[:seq_length]\n",
    "        input_seq = torch.tensor(sequence[:-1], dtype=torch.long)  # Входная последовательность\n",
    "        target_seq = torch.tensor(sequence[1:], dtype=torch.long)  # Целевая последовательность\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Функция для выравнивания последовательностей в батче\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = rnn_utils.pad_sequence(inputs, batch_first=True, padding_value=char_to_idx[' '])\n",
    "    targets_padded = rnn_utils.pad_sequence(targets, batch_first=True, padding_value=char_to_idx[' '])\n",
    "    return inputs_padded, targets_padded\n",
    "\n",
    "# Создаем DataLoader с функцией collate_fn\n",
    "dataset = SimpsonsDataset(sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f715779b-3880-4f09-8c3f-3898c0374df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class RNNCellModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
    "        super(RNNCellModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNNCell(embedding_dim, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs = []\n",
    "        for i in range(embedded.size(1)):\n",
    "            hidden = self.rnn(embedded[:, i], hidden)\n",
    "            output = self.fc(hidden)\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "        return torch.cat(outputs, dim=1), hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ce01128-ea6d-4a58-905e-445120463bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "model = RNNCellModel(vocab_size, embedding_dim, hidden_size)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Функция обучения модели\n",
    "def train(model, dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Эпоха {epoch+1}, Потеря: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0d677c8-14c5-4942-89b0-541d82e378fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Потеря: 1.1589\n",
      "Эпоха 2, Потеря: 0.9036\n",
      "Эпоха 3, Потеря: 0.8367\n",
      "Эпоха 4, Потеря: 0.7954\n",
      "Эпоха 5, Потеря: 0.7680\n",
      "Эпоха 6, Потеря: 0.7465\n",
      "Эпоха 7, Потеря: 0.7319\n",
      "Эпоха 8, Потеря: 0.7206\n",
      "Эпоха 9, Потеря: 0.7092\n",
      "Эпоха 10, Потеря: 0.7021\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "train(model, dataloader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f3ade-35b0-4a4d-b97c-7dbf4b3680e1",
   "metadata": {},
   "source": [
    "2. Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a93f861-5643-4e7e-a342-6afb65ec66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст: homer simpson the start you see the start you see the start you see the start you see the start you see the start\n"
     ]
    }
   ],
   "source": [
    "# Функция для генерации текста\n",
    "def generate_text(model, start_text, length=100):\n",
    "    model.eval()\n",
    "    generated_text = start_text\n",
    "    input_seq = torch.tensor([char_to_idx[c] for c in start_text], dtype=torch.long).unsqueeze(0)\n",
    "    hidden = model.init_hidden(1)\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        predicted_char = torch.argmax(output[:, -1, :], dim=1).item()\n",
    "        generated_text += idx_to_char[predicted_char]\n",
    "        input_seq = torch.tensor([[predicted_char]], dtype=torch.long)\n",
    "    return generated_text\n",
    "\n",
    "# Генерация текста\n",
    "start_text = \"homer simpson\"\n",
    "generated_text = generate_text(model, start_text, length=100)\n",
    "print(f\"Сгенерированный текст: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eaf332dc-d070-46f1-b8dc-7f42aff3e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст с температурой 0.8: homer simpson bely but know they can you soog a simpson you find well a bad some it done take you good to school \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Функция для генерации текста с температурой\n",
    "def generate_text_with_temperature(model, start_text, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated_text = start_text\n",
    "    input_seq = torch.tensor([char_to_idx[c] for c in start_text], dtype=torch.long).unsqueeze(0)\n",
    "    hidden = model.init_hidden(1)\n",
    "    \n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        # Используем температуру для регулирования вероятностей\n",
    "        output = output[:, -1, :] / temperature\n",
    "        probabilities = F.softmax(output, dim=-1)\n",
    "        predicted_char_idx = torch.multinomial(probabilities, num_samples=1).item()\n",
    "        \n",
    "        generated_text += idx_to_char[predicted_char_idx]\n",
    "        input_seq = torch.tensor([[predicted_char_idx]], dtype=torch.long)\n",
    "        \n",
    "    return generated_text\n",
    "\n",
    "# Генерация текста с температурой\n",
    "start_text = \"homer simpson\"\n",
    "temperature = 0.8  # Экспериментируй с разными значениями (например, 0.5, 1.0, 1.5)\n",
    "generated_text = generate_text_with_temperature(model, start_text, length=100, temperature=temperature)\n",
    "print(f\"Сгенерированный текст с температурой {temperature}: {generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9549f-8ca2-4a1d-ab05-7d4f143a65ae",
   "metadata": {},
   "source": [
    "**Пробуем улучшить модель**  \n",
    "\n",
    "1) Введём специальный символ паддинга, который не является частью реальных данных;\n",
    "2) При паддинге используем padding_value=padding_value, а при определении функции потерь используйте ignore_index=padding_value\n",
    "3) Используем nn.RNNCell вместо nn.RNN\n",
    "4) Инициализация скрытого состояния\n",
    "5) Замаскируем функции потерь\n",
    "6) Увеличим размер данных\n",
    "7) Увеличим количество эпох\n",
    "8) Заменим nn.RNN на nn.LSTM, тк лучше справляется с долгосрочными зависимостями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6150961-9fcc-4207-9348-56410369de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс пробела: 0\n",
      "Индекс PAD_TOKEN: 41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загрузка данных из файла\n",
    "file_path = 'C:/Users/Yaros/Downloads/simpsons_script_lines.csv'\n",
    "simpsons_data = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Извлекаем нормализованный текст\n",
    "phrases = simpsons_data['normalized_text'].dropna().tolist()\n",
    "\n",
    "# Ограничиваем количество фраз для тестирования\n",
    "phrases = phrases[:10000]\n",
    "\n",
    "# Преобразуем символы в индексы\n",
    "PAD_TOKEN = '<PAD>'\n",
    "chars = sorted(list(set(''.join(phrases)))) + [PAD_TOKEN]\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "padding_value = char_to_idx[PAD_TOKEN]\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Проверяем индексы символов пробела и паддинга\n",
    "print(f\"Индекс пробела: {char_to_idx[' ']}\")\n",
    "print(f\"Индекс PAD_TOKEN: {padding_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6bd92533-f313-4b2f-a982-9db2121f6421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 27, 0, 13, 15, 32, 33, 13, 24, 24, 37, 0, 21, 32, 0, 35, 13, 31, 0, 13, 0, 24, 21, 32, 32, 24, 17, 0, 27, 18, 0, 14, 27, 32, 20, 0, 31, 27, 25, 17, 32, 21, 25, 17, 31, 0, 35, 20, 17, 26, 0, 13, 0, 16, 21, 31, 17, 13, 31, 17, 0, 21, 31, 0, 21, 26, 0, 13, 24, 24, 0, 32, 20, 17, 0, 25, 13, 19, 13, 38, 21, 26, 17, 31, 0, 13, 26, 16, 0, 13, 24, 24, 0, 32, 20, 17, 0, 26, 17, 35, 31, 0, 31, 20, 27, 35, 31, 0, 21, 32, 31, 0, 27, 26, 24, 37, 0, 26, 13, 32, 33, 30, 13, 24, 0, 32, 20, 13, 32, 0, 37, 27, 33, 0, 32, 20, 21, 26, 23, 0, 37, 27, 33, 0, 20, 13, 34, 17, 0, 21, 32] no actually it was a little of both sometimes when a disease is in all the magazines and all the news shows its only natural that you think you have it\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем текст в числовые последовательности\n",
    "def text_to_sequence(text):\n",
    "    return [char_to_idx.get(char, padding_value) for char in text]\n",
    "\n",
    "sequences = [text_to_sequence(phrase) for phrase in phrases]\n",
    "\n",
    "# Проверим результат преобразования на одном примере\n",
    "print(sequences[0], phrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f45398f7-3652-4f49-89d6-3552605dc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных: паддинг и деление на батчи\n",
    "class SimpsonsDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        # Ограничиваем длину последовательности до seq_length\n",
    "        seq_length = 100\n",
    "        sequence = sequence[:seq_length]\n",
    "        input_seq = torch.tensor(sequence[:-1], dtype=torch.long)  # Входная последовательность\n",
    "        target_seq = torch.tensor(sequence[1:], dtype=torch.long)  # Целевая последовательность\n",
    "        return input_seq, target_seq\n",
    "\n",
    "# Функция для выравнивания последовательностей в батче\n",
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)\n",
    "    inputs_padded = rnn_utils.pad_sequence(inputs, batch_first=True, padding_value=padding_value)\n",
    "    targets_padded = rnn_utils.pad_sequence(targets, batch_first=True, padding_value=padding_value)\n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9963cd48-ec0c-4339-8c5d-da78aa8bb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataLoader с функцией collate_fn\n",
    "dataset = SimpsonsDataset(sequences)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Определение модели\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_size))\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "dropout = 0.2\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "# Получаем частоты символов\n",
    "all_text = ''.join(phrases)\n",
    "char_counts = Counter(all_text)\n",
    "pad_idx = char_to_idx[PAD_TOKEN]\n",
    "\n",
    "char_freq = np.array([char_counts.get(char, 1) for char in chars], dtype=np.float32)\n",
    "char_freq[pad_idx] = 0.0\n",
    "\n",
    "class_weights = 1.0 / (char_freq + 1e-6)\n",
    "class_weights[pad_idx] = 0.0\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=padding_value, weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6193ee00-38a0-4350-b628-c184544bdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обучения с индикатором прогресса\n",
    "def train(model, dataloader, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Эпоха {epoch+1}\")\n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            optimizer.zero_grad()\n",
    "            outputs, hidden = model(inputs, hidden)\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Эпоха {epoch+1}, Средняя потеря: {avg_loss:.4f}\")\n",
    "\n",
    "def generate_text(model, start_text, length=100, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated_text = start_text\n",
    "    input_seq = torch.tensor([char_to_idx.get(c, padding_value) for c in start_text], dtype=torch.long).unsqueeze(0)\n",
    "    hidden = model.init_hidden(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        input_char = input_seq[:, -1].unsqueeze(1)\n",
    "\n",
    "        for i in range(length):\n",
    "            output, hidden = model(input_char, hidden)\n",
    "            output = output[:, -1, :] / temperature\n",
    "            probabilities = F.softmax(output, dim=-1)\n",
    "            space_idx = char_to_idx[' ']\n",
    "            probabilities[0][space_idx] *= 0.1\n",
    "            probabilities = probabilities / probabilities.sum()\n",
    "\n",
    "            predicted_char_idx = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            generated_char = idx_to_char[predicted_char_idx]\n",
    "            generated_text += generated_char\n",
    "\n",
    "            input_char = torch.tensor([[predicted_char_idx]], dtype=torch.long)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46ee9fa4-6687-4a01-818b-d23740abd061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.18it/s, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1, Средняя потеря: 2.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.92it/s, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2, Средняя потеря: 2.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.86it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3, Средняя потеря: 2.2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 4: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.70it/s, loss=2.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4, Средняя потеря: 2.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.88it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5, Средняя потеря: 2.0478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 6: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.66it/s, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 6, Средняя потеря: 1.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 7: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.00it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 7, Средняя потеря: 1.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 8: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.54it/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 8, Средняя потеря: 1.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 9: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.87it/s, loss=1.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 9, Средняя потеря: 1.7198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 10: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.14it/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 10, Средняя потеря: 1.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 11: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 29.92it/s, loss=1.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 11, Средняя потеря: 1.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 12: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.35it/s, loss=0.989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 12, Средняя потеря: 1.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 13: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.46it/s, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 13, Средняя потеря: 1.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 14: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.58it/s, loss=1.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 14, Средняя потеря: 1.5091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 15: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.65it/s, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 15, Средняя потеря: 1.4866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 16: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.75it/s, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 16, Средняя потеря: 1.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 17: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.87it/s, loss=0.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 17, Средняя потеря: 1.4465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 18: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.64it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 18, Средняя потеря: 1.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 19: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.64it/s, loss=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 19, Средняя потеря: 1.3772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 20: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.88it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 20, Средняя потеря: 1.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 21: 100%|████████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.52it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 21, Средняя потеря: 1.3586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 22: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.34it/s, loss=0.681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 22, Средняя потеря: 1.3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 23: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.56it/s, loss=0.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 23, Средняя потеря: 1.3188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 24: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.46it/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 24, Средняя потеря: 1.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 25: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.19it/s, loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 25, Средняя потеря: 1.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 26: 100%|████████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.30it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 26, Средняя потеря: 1.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 27: 100%|███████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.57it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 27, Средняя потеря: 1.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 28: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.23it/s, loss=1.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 28, Средняя потеря: 1.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 29: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.95it/s, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 29, Средняя потеря: 1.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 30: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.25it/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 30, Средняя потеря: 1.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 31: 100%|███████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.53it/s, loss=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 31, Средняя потеря: 1.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 32: 100%|███████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.69it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 32, Средняя потеря: 1.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 33: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 30.91it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 33, Средняя потеря: 1.1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 34: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.28it/s, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 34, Средняя потеря: 1.1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 35: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.21it/s, loss=1.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 35, Средняя потеря: 1.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 36: 100%|██████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.27it/s, loss=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 36, Средняя потеря: 1.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 37: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.20it/s, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 37, Средняя потеря: 1.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 38: 100%|███████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.47it/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 38, Средняя потеря: 1.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 39: 100%|███████████████████████████████████████████████████████████| 313/313 [00:10<00:00, 31.18it/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 39, Средняя потеря: 1.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 40: 100%|███████████████████████████████████████████████████████████| 313/313 [00:09<00:00, 31.60it/s, loss=1.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 40, Средняя потеря: 1.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29c60cf5-2650-4b65-8dca-10c6c0955433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст:\n",
      "homer simpson: malmmy coming strownbyodboxeduck-a-way-jistingse guys couldventing awraystiaking mysibally with alle\n"
     ]
    }
   ],
   "source": [
    "# Генерация текста после обучения\n",
    "start_text = \"homer simpson: \"\n",
    "temperature = 0.8\n",
    "generated_text = generate_text(model, start_text, length=100, temperature=temperature)\n",
    "print(f\"Сгенерированный текст:\\n{generated_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f14302-861b-4cf6-b13c-06268019a800",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В ходе работы я попытался построить нейронную сеть на основе RNN для генерации текстов с выражениями героев сериала «Симпсоны». Я столкнулся с рядом технических проблем и постепенно их устранял, улучшая модель и её производительность.\n",
    "\n",
    "### Основные этапы работы:\n",
    "\n",
    "1) Создание RNN-модели на PyTorch\n",
    "\n",
    "    - Изначально я построил модель с использованием nn.RNNCell, но возникли сложности с генерацией текста.\n",
    "    - Обнаружил ошибки в обработке входных данных и инициализации скрытых состояний.\n",
    "      \n",
    "2) Исправление функции генерации текста\n",
    "\n",
    "    - Модель генерировала пустые строки или повторяющие пробелы.\n",
    "    - Я скорректировал функцию генерации текста, обеспечив правильное обновление входных данных и скрытых состояний в цикле генерации.\n",
    "    - Добавил специальный символ паддинга <PAD> и скорректировал словари char_to_idx и idx_to_char.\n",
    "      \n",
    "3) Улучшение архитектуры модели\n",
    "\n",
    "    - Заменил nn.RNNCell на nn.LSTM для лучшего захвата долгосрочных зависимостей.\n",
    "    - Добавил дополнительные слои LSTM и слои Dropout для предотвращения переобучения.\n",
    "    - Ввёл веса классов в функцию потерь для обработки дисбаланса символов в данных.\n",
    "      \n",
    "4) Обработка данных и увеличение объёма обучающей выборки\n",
    "\n",
    "    - Убедился, что символы пробела и паддинга имеют разные индексы и правильно обрабатываются.\n",
    "    - Увеличил объём данных для обучения, убрав ограничение на количество фраз.\n",
    "    - Провёл анализ частотности символов и скорректировал веса классов.\n",
    "      \n",
    "5) Настройка гиперпараметров и обучение модели\n",
    "\n",
    "    - Увеличил количество эпох обучения и настроил скорость обучения.\n",
    "    - Добавил индикаторы прогресса в функцию обучения для мониторинга процесса.\n",
    "    - Провёл экспериментирование с размером эмбеддингов и скрытых слоёв.\n",
    "      \n",
    "6) Полученные результаты и дальнейшие шаги\n",
    "\n",
    "    - Модель начала генерировать более разнообразный текст, но он всё ещё не был полностью осмысленным.\n",
    "    - Понял, что для улучшения качества генерации необходимо:  \n",
    "        a) Увеличить объём данных и их качество.  \n",
    "        b) Повысить сложность модели, возможно, перейти на использование более современных архитектур.  \n",
    "        c) Рассмотреть возможность использования предварительно обученных моделей, таких как GPT-2.  \n",
    "      \n",
    "### Заключение\n",
    "\n",
    "В результате проделанной работы я существенно улучшил модель и её способность генерировать текст. Однако генерация осмысленного и связного текста требует более глубокого подхода, включая использование большего объёма данных и более мощных моделей. Дальнейшие шаги включают в себя:\n",
    "\n",
    "    - Расширение обучающей выборки: использование полного датасета и его тщательная предобработка.\n",
    "    - Улучшение модели: экспериментирование с гиперпараметрами, увеличение числа слоёв и нейронов.\n",
    "    - Применение современных методов: изучение и внедрение моделей трансформеров и предварительно обученных языковых моделей.\n",
    "    - Анализ результатов: регулярное мониторирование качества генерации и корректировка подхода на основе полученных данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
